{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a718129-ab37-4eb1-b221-8583d6c3de03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Irfan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Irfan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Irfan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# For topic modeling\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Download NLTK Resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc363d71-5804-4944-b99d-b08b52a9f038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Document\n",
      "0  Rafael Nadal Joins Roger Federer in Missing U.S. Open\n",
      "1             Rafael Nadal Is Out of the Australian Open\n",
      "2                         Biden Announces Virus Measures\n",
      "3                       Biden's Virus Plans Meet Reality\n",
      "4                        Where Biden's Virus Plan Stands\n"
     ]
    }
   ],
   "source": [
    "# Define stop words and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"Rafael Nadal Joins Roger Federer in Missing U.S. Open\",\n",
    "    \"Rafael Nadal Is Out of the Australian Open\",\n",
    "    \"Biden Announces Virus Measures\",\n",
    "    \"Biden's Virus Plans Meet Reality\",\n",
    "    \"Where Biden's Virus Plan Stands\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(documents, columns=[\"Document\"])\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d62a888-ce2f-40cc-8c43-86ce9b4ca204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['rafael', 'nadal', 'join', 'roger', 'federer', 'missing', 'open'], ['rafael', 'nadal', 'australian', 'open'], ['biden', 'announces', 'virus', 'measure'], ['biden', 'virus', 'plan', 'meet', 'reality'], ['biden', 'virus', 'plan', 'stand']]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess function\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize and lowercase\n",
    "    tokens = [token for token in tokens if token.isalnum()]  # Remove non-alphanumeric tokens\n",
    "    tokens = [token for token in tokens if token not in stop_words]  # Remove stopwords\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatize tokens\n",
    "    return tokens\n",
    "\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Print the preprocessed documents in the desired format\n",
    "print(preprocessed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e156466c-6b54-4858-a182-8be3ae3b553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gensim Dictionary object from the preprocessed documents\n",
    "dictionary = corpora.Dictionary(preprocessed_documents)\n",
    "\n",
    "# Convert each preprocessed document into a bag-of-words representation using the dictionary\n",
    "corpus = [dictionary.doc2bow(doc) for doc in preprocessed_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9172cdc2-8f6d-4bb3-9498-9374a9c329cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus, num_topics=2, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb4c58ee-6b4e-407e-a8e4-467f9c225ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with Articles and Topic:\n",
      "                                                 Article  Topic\n",
      "0  Rafael Nadal Joins Roger Federer in Missing U.S. Open      0\n",
      "1             Rafael Nadal Is Out of the Australian Open      0\n",
      "2                         Biden Announces Virus Measures      1\n",
      "3                       Biden's Virus Plans Meet Reality      1\n",
      "4                        Where Biden's Virus Plan Stands      1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Interpret Results\n",
    "\n",
    "# empty list to store dominant topic labels for each document\n",
    "article_labels = []\n",
    "\n",
    "# iterate over each processed document\n",
    "for i, doc in enumerate(preprocessed_documents):\n",
    "    # for each document, convert to bag-of-words representation\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    # get list of topic probabilities\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    # determine topic with highest probability\n",
    "    dominant_topic = max(topics, key=lambda x: x[1])[0]\n",
    "    # append the dominant topic to the list\n",
    "    article_labels.append(dominant_topic)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\"Article\": documents, \"Topic\": article_labels})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(\"Table with Articles and Topic:\")\n",
    "print(df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d97f534b-823a-428a-8741-56d9e110441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Terms for Each Topic:\n",
      "Topic 0:\n",
      "- \"nadal\" (weight: 0.131)\n",
      "- \"rafael\" (weight: 0.131)\n",
      "- \"open\" (weight: 0.131)\n",
      "- \"federer\" (weight: 0.079)\n",
      "- \"roger\" (weight: 0.079)\n",
      "- \"missing\" (weight: 0.079)\n",
      "- \"join\" (weight: 0.079)\n",
      "- \"australian\" (weight: 0.079)\n",
      "- \"biden\" (weight: 0.027)\n",
      "- \"virus\" (weight: 0.027)\n",
      "Topic 1:\n",
      "- \"virus\" (weight: 0.166)\n",
      "- \"biden\" (weight: 0.166)\n",
      "- \"plan\" (weight: 0.119)\n",
      "- \"measure\" (weight: 0.071)\n",
      "- \"announces\" (weight: 0.071)\n",
      "- \"meet\" (weight: 0.071)\n",
      "- \"stand\" (weight: 0.071)\n",
      "- \"reality\" (weight: 0.071)\n",
      "- \"open\" (weight: 0.024)\n",
      "- \"rafael\" (weight: 0.024)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the top terms for each topic\n",
    "print(\"Top Terms for Each Topic:\")\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f\"Topic {idx}:\")\n",
    "    terms = [term.strip() for term in topic.split(\"+\")]\n",
    "    for term in terms:\n",
    "        weight, word = term.split(\"*\")\n",
    "        print(f\"- {word.strip()} (weight: {weight.strip()})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e204a-6560-4512-a405-e25a8d424782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
